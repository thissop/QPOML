<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>qpoml.utilities API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>qpoml.utilities</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import numpy 
import pandas as pd
import pandas 
import warnings

### BASIC ###

def preprocess1d(x, preprocess): 
    
    r&#39;&#39;&#39;
    preprocess : list, str
        If it&#39;s a list, then preprocess[0] is min value for norm, and ...[1] is max value for norm 
    &#39;&#39;&#39;
    
    if type(preprocess) is list: 
        min_value = preprocess[0]
        max_value = preprocess[1]
        modified = (x-min_value)/(max_value-min_value) 
        modified = modified*(1 - 0.1) + 0.1 # so it will be output as 0.1-1 range 
    elif type(preprocess) is str: 
        if preprocess == &#39;as-is&#39;: 
            modified = x 
        elif preprocess == &#39;normalize&#39;: 
            min_value = np.min(x)
            max_value = np.max(x)
            modified = (x-min_value)/(max_value-min_value)
            modified = modified*(1 - 0.1) + 0.1
        elif preprocess == &#39;standardize&#39;: 
            mean = np.mean(x)
            sigma = np.std(x)
            modified = (x-mean)/sigma
        elif preprocess == &#39;median&#39;: 
            modified = x/np.median(x)
        else: 
            raise Exception(&#39;&#39;)
    
    
    return modified

### POST LOAD ### 

def correlation_matrix(data:pandas.DataFrame): # &lt;== I don&#39;t think this works for spectrums? 

    temp_df = data.select_dtypes([&#39;number&#39;])
    corr = temp_df.corr()
    cols = list(temp_df)
    
    return corr, cols

def dendrogram(data:pandas.DataFrame):
    from scipy.stats import spearmanr
    from scipy.cluster import hierarchy
    from scipy.spatial.distance import squareform

    temp = data.select_dtypes([&#39;number&#39;])
    cols = list(temp)

    # below from sklearn documentation 

    # Ensure the correlation matrix is symmetric
    corr = spearmanr(temp).correlation
    corr = (corr + corr.T) / 2
    np.fill_diagonal(corr, 1)

    # We convert the correlation matrix to a distance matrix before performing
    # hierarchical clustering using Ward&#39;s linkage.
    distance_matrix = 1 - np.abs(corr)
    dist_linkage = hierarchy.ward(squareform(distance_matrix))
    
    return corr, dist_linkage, cols 

def calculate_vif(data:pandas.DataFrame): 
    from statsmodels.stats.outliers_influence import variance_inflation_factor as vif
    
    temp = data.select_dtypes([&#39;number&#39;])

    vif_df = pd.DataFrame()
    vif_df[&#39;VIF&#39;] = [vif(temp.values, i) for i in range(temp.shape[1])]
    vif_df[&#39;Column&#39;] = list(temp)

    vif_df.sort_values(&#39;VIF&#39;, ascending=True)

    return vif_df 

### POST EVALUATION ### 

def results_regression(y_test:numpy.array, predictions:numpy.array, which:list, 
                       regression_x:numpy.array=None, regression_y:numpy.array=None): # will work best with result vectors of my design 
    r&#39;&#39;&#39;
    
    Execute &#34;results regression&#34; on predictions based on their true values.  

    Parameters
    ----------

    y_test : numpy.array 
        True values to compare predicted ones to 

    predictions : numpy.array
        Array of predicted values 

    which : list 
        List of pythonic indices corresponding to the value(s) in the `y_test`/`predictions` vectors upon which `results_regression` should be run; e.g. if QPO vector is `[frequency,width,amplitude]`, `what=[0]` will run `results_regression` on frequency only because only the zeroth item in every predicted vector, the QPO frequency in this case, will be concatenated to the flattened arrays for regression. Similarly, if the QPO prediction vectors followed the form `[First QPO Frequency, First QPO Width, Second QPO Frequency, Second QPO Width]`, `what=[0,2]` would compute `results_regression` on only a concatenated array of First and Second QPO Frequencies.      

    Returns
    -------

    variable_name : type
        Description 

    regression_x : numpy.array 
        Flattened (from potentially concatenated array) of true values 

    regression_y : numpy.array 
        Flattened (from potentially concatenated array) of predicted values 
    
    line_tuple : tuple 
        Returns `(m,b)`, i.e. best fit slope and intercept

    stats_tuple : tuple   
        Returns `(r, pval, stderr, intercept_stderr)`; see documentation for `scipy.stats.linregress`

    &#39;&#39;&#39;
    
    from scipy.stats import linregress 
    
    if regression_x is None and regression_y is None: 
        regression_x = np.transpose(np.array(y_test))
        regression_y = np.transpose(np.array(predictions))

        regression_x, regression_y = (i[which] for i in (regression_x, regression_y)) 

    regression_x = regression_x.flatten().astype(float)
    regression_y = regression_y.flatten().astype(float)

    linregress_result = linregress(regression_x, regression_y) 

    return regression_x, regression_y, linregress_result 
    
def feature_importances(model, X_test, y_test, feature_names:list, kind:str=&#39;kernel-shap&#39;):
    
    import shap
    
    importances_df = None
    shap_values = None
    feature_importances_arr = None
    sort_idx = None 

    if kind==&#39;default&#39;:
        if hasattr(model, &#39;feature_importances_&#39;): 
            feature_importances_arr = model.feature_importances_
                
    elif kind==&#39;permutation&#39;: 
        
        from sklearn.inspection import permutation_importance

        permutation_importances = permutation_importance(estimator=model, X=X_test, y=y_test)
        feature_importances_arr = permutation_importances[&#39;importances_mean&#39;]

        sort_idx = np.argsort(feature_importances_arr)[::-1]

        importances_df = pd.DataFrame(permutation_importances.importances[sort_idx].T, columns=feature_names[sort_idx])
        
    elif kind==&#39;kernel-shap&#39;: 
        warnings.warn(&#39;need to implement check to see if model is supported&#39;)
        explainer = shap.KernelExplainer(model.predict, X_test)
        shap_values = explainer.shap_values(X_test)
        shap_values = np.array(shap_values).T
        feature_importances_arr = np.array([np.mean(np.abs(i)) for i in shap_values])

    elif kind==&#39;tree-shap&#39;: 
        warnings.warn(&#39;need to check if possible!&#39;)
        explainer = shap.TreeExplainer(model)
        shap_values = np.array(explainer.shap_values(X_test))
        shap_values = np.array(shap_values).T
        feature_importances_arr = np.array([np.mean(np.abs(i)) for i in shap_values])

    else: 
        raise Exception(&#39;&#39;)

    if sort_idx is None: 
        sort_idx = np.argsort(feature_importances_arr)[::-1]

    sort_idx = sort_idx.astype(int)

    feature_importances_arr = feature_importances_arr[sort_idx]
    feature_names = np.array(feature_names)[sort_idx]

    if kind==&#39;tree-shap&#39; or kind==&#39;kernel-shap&#39;: 
        importances_df = pd.DataFrame()
        for index in range(len(feature_names)): 
            importances_df[feature_names[index]] = [feature_importances_arr[index]]

    print(&#39;this is really jank fix it!&#39;)
    return feature_importances_arr, feature_names, importances_df
    
def confusion_matrix(y_test:numpy.array, predictions:numpy.array): 
    from sklearn.metrics import confusion_matrix, accuracy_score

    y_test = np.array(y_test).flatten()
    predictions = np.array(predictions).flatten()  

    cm = confusion_matrix(y_test, predictions)
    acc = accuracy_score(y_test, predictions)

    return cm, acc

### TO DO ###
r&#39;&#39;&#39;

# these are not that important to me right now, but should be eventually (because convenience can make the package marketable) ... I think they can&#39;t be static...they need to be instance 

def remove_by_vif(cutoff_value): # remove columns from context with vif more than cutoff ... note that multicollinearity is not a concern for pure accuracy, mainly a concern when dealing with feature importances, which is important in elucidating useful takeaways; only applied to context 
    self.check_loaded(&#39;remove_by_vif&#39;)

    import statsmodels.api as sm
    from statsmodels.stats.outliers_influence import variance_inflation_factor as vif

    vif_info = pd.DataFrame()
    vif_info[&#39;VIF&#39;] = [vif(X.values, i) for i in range(X.shape[1])]
    vif_info[&#39;Column&#39;] = X.columns
    vif_info.sort_values(&#39;VIF&#39;, ascending=True)

    mask = np.where(vif_info[&#39;VIF&#39;]&lt;5)[0]

    ols_cols = vif_info[&#39;Column&#39;][mask]

def remove_from_dendrogram(cutoff_value): # rename? 
    pass 

def pca_transform(): # once these happen, context_df and arrays are changed to place holder names with transformed vectors;  only applied to context
    self.check_loaded(&#39;pca_transform&#39;) # https://github.com/thissop/MAXI-J1535/blob/main/code/machine-learning/December-%202021-2022/very_initial_sanity_check.ipynb

def mds_transform(): # only applied to context
    self.check_loaded(&#39;mds_transform&#39;)



&#39;&#39;&#39;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="qpoml.utilities.calculate_vif"><code class="name flex">
<span>def <span class="ident">calculate_vif</span></span>(<span>data: pandas.core.frame.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_vif(data:pandas.DataFrame): 
    from statsmodels.stats.outliers_influence import variance_inflation_factor as vif
    
    temp = data.select_dtypes([&#39;number&#39;])

    vif_df = pd.DataFrame()
    vif_df[&#39;VIF&#39;] = [vif(temp.values, i) for i in range(temp.shape[1])]
    vif_df[&#39;Column&#39;] = list(temp)

    vif_df.sort_values(&#39;VIF&#39;, ascending=True)

    return vif_df </code></pre>
</details>
</dd>
<dt id="qpoml.utilities.confusion_matrix"><code class="name flex">
<span>def <span class="ident">confusion_matrix</span></span>(<span>y_test: <built-in function array>, predictions: <built-in function array>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def confusion_matrix(y_test:numpy.array, predictions:numpy.array): 
    from sklearn.metrics import confusion_matrix, accuracy_score

    y_test = np.array(y_test).flatten()
    predictions = np.array(predictions).flatten()  

    cm = confusion_matrix(y_test, predictions)
    acc = accuracy_score(y_test, predictions)

    return cm, acc</code></pre>
</details>
</dd>
<dt id="qpoml.utilities.correlation_matrix"><code class="name flex">
<span>def <span class="ident">correlation_matrix</span></span>(<span>data: pandas.core.frame.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def correlation_matrix(data:pandas.DataFrame): # &lt;== I don&#39;t think this works for spectrums? 

    temp_df = data.select_dtypes([&#39;number&#39;])
    corr = temp_df.corr()
    cols = list(temp_df)
    
    return corr, cols</code></pre>
</details>
</dd>
<dt id="qpoml.utilities.dendrogram"><code class="name flex">
<span>def <span class="ident">dendrogram</span></span>(<span>data: pandas.core.frame.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dendrogram(data:pandas.DataFrame):
    from scipy.stats import spearmanr
    from scipy.cluster import hierarchy
    from scipy.spatial.distance import squareform

    temp = data.select_dtypes([&#39;number&#39;])
    cols = list(temp)

    # below from sklearn documentation 

    # Ensure the correlation matrix is symmetric
    corr = spearmanr(temp).correlation
    corr = (corr + corr.T) / 2
    np.fill_diagonal(corr, 1)

    # We convert the correlation matrix to a distance matrix before performing
    # hierarchical clustering using Ward&#39;s linkage.
    distance_matrix = 1 - np.abs(corr)
    dist_linkage = hierarchy.ward(squareform(distance_matrix))
    
    return corr, dist_linkage, cols </code></pre>
</details>
</dd>
<dt id="qpoml.utilities.feature_importances"><code class="name flex">
<span>def <span class="ident">feature_importances</span></span>(<span>model, X_test, y_test, feature_names: list, kind: str = 'kernel-shap')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def feature_importances(model, X_test, y_test, feature_names:list, kind:str=&#39;kernel-shap&#39;):
    
    import shap
    
    importances_df = None
    shap_values = None
    feature_importances_arr = None
    sort_idx = None 

    if kind==&#39;default&#39;:
        if hasattr(model, &#39;feature_importances_&#39;): 
            feature_importances_arr = model.feature_importances_
                
    elif kind==&#39;permutation&#39;: 
        
        from sklearn.inspection import permutation_importance

        permutation_importances = permutation_importance(estimator=model, X=X_test, y=y_test)
        feature_importances_arr = permutation_importances[&#39;importances_mean&#39;]

        sort_idx = np.argsort(feature_importances_arr)[::-1]

        importances_df = pd.DataFrame(permutation_importances.importances[sort_idx].T, columns=feature_names[sort_idx])
        
    elif kind==&#39;kernel-shap&#39;: 
        warnings.warn(&#39;need to implement check to see if model is supported&#39;)
        explainer = shap.KernelExplainer(model.predict, X_test)
        shap_values = explainer.shap_values(X_test)
        shap_values = np.array(shap_values).T
        feature_importances_arr = np.array([np.mean(np.abs(i)) for i in shap_values])

    elif kind==&#39;tree-shap&#39;: 
        warnings.warn(&#39;need to check if possible!&#39;)
        explainer = shap.TreeExplainer(model)
        shap_values = np.array(explainer.shap_values(X_test))
        shap_values = np.array(shap_values).T
        feature_importances_arr = np.array([np.mean(np.abs(i)) for i in shap_values])

    else: 
        raise Exception(&#39;&#39;)

    if sort_idx is None: 
        sort_idx = np.argsort(feature_importances_arr)[::-1]

    sort_idx = sort_idx.astype(int)

    feature_importances_arr = feature_importances_arr[sort_idx]
    feature_names = np.array(feature_names)[sort_idx]

    if kind==&#39;tree-shap&#39; or kind==&#39;kernel-shap&#39;: 
        importances_df = pd.DataFrame()
        for index in range(len(feature_names)): 
            importances_df[feature_names[index]] = [feature_importances_arr[index]]

    print(&#39;this is really jank fix it!&#39;)
    return feature_importances_arr, feature_names, importances_df</code></pre>
</details>
</dd>
<dt id="qpoml.utilities.preprocess1d"><code class="name flex">
<span>def <span class="ident">preprocess1d</span></span>(<span>x, preprocess)</span>
</code></dt>
<dd>
<div class="desc"><p>preprocess : list, str
If it's a list, then preprocess[0] is min value for norm, and &hellip;[1] is max value for norm</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess1d(x, preprocess): 
    
    r&#39;&#39;&#39;
    preprocess : list, str
        If it&#39;s a list, then preprocess[0] is min value for norm, and ...[1] is max value for norm 
    &#39;&#39;&#39;
    
    if type(preprocess) is list: 
        min_value = preprocess[0]
        max_value = preprocess[1]
        modified = (x-min_value)/(max_value-min_value) 
        modified = modified*(1 - 0.1) + 0.1 # so it will be output as 0.1-1 range 
    elif type(preprocess) is str: 
        if preprocess == &#39;as-is&#39;: 
            modified = x 
        elif preprocess == &#39;normalize&#39;: 
            min_value = np.min(x)
            max_value = np.max(x)
            modified = (x-min_value)/(max_value-min_value)
            modified = modified*(1 - 0.1) + 0.1
        elif preprocess == &#39;standardize&#39;: 
            mean = np.mean(x)
            sigma = np.std(x)
            modified = (x-mean)/sigma
        elif preprocess == &#39;median&#39;: 
            modified = x/np.median(x)
        else: 
            raise Exception(&#39;&#39;)
    
    
    return modified</code></pre>
</details>
</dd>
<dt id="qpoml.utilities.results_regression"><code class="name flex">
<span>def <span class="ident">results_regression</span></span>(<span>y_test: <built-in function array>, predictions: <built-in function array>, which: list, regression_x: <built-in function array> = None, regression_y: <built-in function array> = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Execute "results regression" on predictions based on their true values.
</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y_test</code></strong> :&ensp;<code>numpy.array </code></dt>
<dd>True values to compare predicted ones to</dd>
<dt><strong><code>predictions</code></strong> :&ensp;<code>numpy.array</code></dt>
<dd>Array of predicted values</dd>
<dt><strong><code>which</code></strong> :&ensp;<code>list </code></dt>
<dd>List of pythonic indices corresponding to the value(s) in the <code>y_test</code>/<code>predictions</code> vectors upon which <code><a title="qpoml.utilities.results_regression" href="#qpoml.utilities.results_regression">results_regression()</a></code> should be run; e.g. if QPO vector is <code>[frequency,width,amplitude]</code>, <code>what=[0]</code> will run <code><a title="qpoml.utilities.results_regression" href="#qpoml.utilities.results_regression">results_regression()</a></code> on frequency only because only the zeroth item in every predicted vector, the QPO frequency in this case, will be concatenated to the flattened arrays for regression. Similarly, if the QPO prediction vectors followed the form <code>[First QPO Frequency, First QPO Width, Second QPO Frequency, Second QPO Width]</code>, <code>what=[0,2]</code> would compute <code><a title="qpoml.utilities.results_regression" href="#qpoml.utilities.results_regression">results_regression()</a></code> on only a concatenated array of First and Second QPO Frequencies.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>variable_name</code></strong> :&ensp;<code>type</code></dt>
<dd>Description</dd>
<dt><strong><code>regression_x</code></strong> :&ensp;<code>numpy.array </code></dt>
<dd>Flattened (from potentially concatenated array) of true values</dd>
<dt><strong><code>regression_y</code></strong> :&ensp;<code>numpy.array </code></dt>
<dd>Flattened (from potentially concatenated array) of predicted values</dd>
<dt><strong><code>line_tuple</code></strong> :&ensp;<code>tuple </code></dt>
<dd>Returns <code>(m,b)</code>, i.e. best fit slope and intercept</dd>
<dt><strong><code>stats_tuple</code></strong> :&ensp;<code>tuple
</code></dt>
<dd>Returns <code>(r, pval, stderr, intercept_stderr)</code>; see documentation for <code>scipy.stats.linregress</code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def results_regression(y_test:numpy.array, predictions:numpy.array, which:list, 
                       regression_x:numpy.array=None, regression_y:numpy.array=None): # will work best with result vectors of my design 
    r&#39;&#39;&#39;
    
    Execute &#34;results regression&#34; on predictions based on their true values.  

    Parameters
    ----------

    y_test : numpy.array 
        True values to compare predicted ones to 

    predictions : numpy.array
        Array of predicted values 

    which : list 
        List of pythonic indices corresponding to the value(s) in the `y_test`/`predictions` vectors upon which `results_regression` should be run; e.g. if QPO vector is `[frequency,width,amplitude]`, `what=[0]` will run `results_regression` on frequency only because only the zeroth item in every predicted vector, the QPO frequency in this case, will be concatenated to the flattened arrays for regression. Similarly, if the QPO prediction vectors followed the form `[First QPO Frequency, First QPO Width, Second QPO Frequency, Second QPO Width]`, `what=[0,2]` would compute `results_regression` on only a concatenated array of First and Second QPO Frequencies.      

    Returns
    -------

    variable_name : type
        Description 

    regression_x : numpy.array 
        Flattened (from potentially concatenated array) of true values 

    regression_y : numpy.array 
        Flattened (from potentially concatenated array) of predicted values 
    
    line_tuple : tuple 
        Returns `(m,b)`, i.e. best fit slope and intercept

    stats_tuple : tuple   
        Returns `(r, pval, stderr, intercept_stderr)`; see documentation for `scipy.stats.linregress`

    &#39;&#39;&#39;
    
    from scipy.stats import linregress 
    
    if regression_x is None and regression_y is None: 
        regression_x = np.transpose(np.array(y_test))
        regression_y = np.transpose(np.array(predictions))

        regression_x, regression_y = (i[which] for i in (regression_x, regression_y)) 

    regression_x = regression_x.flatten().astype(float)
    regression_y = regression_y.flatten().astype(float)

    linregress_result = linregress(regression_x, regression_y) 

    return regression_x, regression_y, linregress_result </code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="qpoml" href="index.html">qpoml</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="qpoml.utilities.calculate_vif" href="#qpoml.utilities.calculate_vif">calculate_vif</a></code></li>
<li><code><a title="qpoml.utilities.confusion_matrix" href="#qpoml.utilities.confusion_matrix">confusion_matrix</a></code></li>
<li><code><a title="qpoml.utilities.correlation_matrix" href="#qpoml.utilities.correlation_matrix">correlation_matrix</a></code></li>
<li><code><a title="qpoml.utilities.dendrogram" href="#qpoml.utilities.dendrogram">dendrogram</a></code></li>
<li><code><a title="qpoml.utilities.feature_importances" href="#qpoml.utilities.feature_importances">feature_importances</a></code></li>
<li><code><a title="qpoml.utilities.preprocess1d" href="#qpoml.utilities.preprocess1d">preprocess1d</a></code></li>
<li><code><a title="qpoml.utilities.results_regression" href="#qpoml.utilities.results_regression">results_regression</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>