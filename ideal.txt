## RAW IDEALIZED WORKFLOW

from qpoml import qpo, context, collection

c = context() 

q = qpo()

pds = pds()

q.plot(ax=None) # returns x and y 

collection = collection(random_state=random_value)

collection.load(qpo_df, context_df, preprocess={}, test_size:0.9, shuffle=True, stratify:str=None, hyper_tuning:)

collection.evaluate(x='qpo', y='context', model='random_forest', optimize='mae', new_collection=None)

## ANNOTATED WORKFLOW 

pds = pds()

pds.find_qpos(method='default')

pds.plot(ax=None, list_of_qpo_objects=None)

c = context()

* future idea: let context be image and incorporate future methods for that to happen
* for now, I should be able to load array of 
* wait......can I let a context file simultaneously have spectrum values and individual scalars? that would really mess up stuff now, maybe future idea

# I think default color palette should be red-blue continuous one 

collection = collection(random_state=random_value)

# random_state
    random state that all operations on this collection will use

collection.load(qpo_df, context_df, preprocess={}, test_size:0.9)

# once a collection has been loaded, you can execute the following methods: 
    * plots
        * plot_correlation_matrix() # qpo, context, both 
        * plot_pairplot(dendogram=False) # because seaborn annoys me; # qpo, context, both  
        * plot_dendogram() # qpo, context
        * plot_vif()  
        * plot_pca_transform(c=col_name) # no colors would make sense here related to context, only those related to qpo 
        * plot_mds_transform() 

        code note: plot routines execute their corresponding routines internally
        note: show steiner some of my code how complicated it is and how much I repeat it ... catalog all the separate modules 
        note: probably need to test everything in the library, and then set all requirements to all working libraries 

    * other
        * correlation_matrix() 
        * dendogram()
        * vif() # from statsmodels.stats.outliers_influence import variance_inflation_factor as vif; only applied to context
        * cull_vif(cutoff_value) # remove columns from context with vif more than cutoff ... note that multicolinearity is not a concern for pure accuracy, mainly a concern when dealing with feature importances, which is important in elucidating useful takeaways; only applied to context 
        * pca_transform() # once these happen, context_df and arrays are changed to place holder names with transformed vectors;  only applied to context
        * mds_transform(); # only applied to context
        * rebin() # if context columns are spectral channels, rebin will rebin them and assign new column names while associating ranges to them. 

# preprocess 
    when loading, preprocess should be dictionary where keys are column names in context_df, 
    and vals are 1. lists if you want to normalize data between certain min max or 2. string set to
    'standardize', 'normalize', or 'categorical' --> if standardize, data will be standardized, if normalize, 
    each column will be normalized based on its own min max, and if categorical, string values will be converted to ints 
    and ints will be preserved as un-normalized ints 

# test_size
    if float, will be proportion of values set to test, if int, will be number of values set to  

collection.evaluate(x='qpo', y='context', model='random_forest') # or a sklearn model, which will be understood 

# once a collection has been evaluated, it has been trained and tested, so 

# test how code would work with multi output versus single vector? my module could simplify both, e.g. but multi output regression under the hood. 

# need to incorporate option for test_size = 0.0, so they could train fully on one collection to test with another. 

# once a collection has been evaluated, you can execute the following methods: 
    * plots
        * plot_confusion_matrix() 
        * plot_results_regression(color=) # column name from either context or parameter name from qpo. if categorical, will plot and label by categories. otherwise, will plot by continuous color (add add color bar?))  
        * plot_feature_importances(color=)  
    
    * other
        * confusion_matrix()
        * results_regression()
        * feature_importances()  # https://github.com/thissop/MAXI-J1535/blob/main/code/machine-learning/December-%202021-2022/multicolinearity_corrected_(after_kfold_cv)_short.ipynb for shapely 

# note: QPOs will not, I repeat, NOT contain more than one QPO! instead, they will be matched to context objects index wise in the pure numpy arrays under the hood 
# very satisfying 

#### BELOW CONTAINS NEW NOTES FROM JUNE 9TH WORK SESH ####
set verbose setting in initialization? if true (default), do progress bar during loading? 


# function header template below: 
    r'''

    One Line Description 

    Parameters
    ----------

    variable_name : type
        Description

    Returns
    -------

    variable_name : type
        Description 

    Examples
    --------
      >>> from astropy.table import Table, TableAttribute
      >>> class MyTable(Table):
      ...     identifier = TableAttribute(default=1)
      >>> t = MyTable(identifier=10)
      >>> t.identifier
      10
      >>> t.meta
      OrderedDict([('__attributes__', {'identifier': 10})])
      
    '''